You use language to gather information, to share information with others, and to make and maintain the many social connections and relationships that fill your life. Where and how that communication occurs has changed rather dramatically in recent years. Most Canadians, 88 percent, have a cellphone and most Canadian homes, 87 percent, have an Internet connection (CRTC, 2019). Almost all, 97 percent, of Canadians 18 to 24 years of age (sometimes referred to as Gen Z or as iGen) own a smart phone and are much more likely to use their smart phones as their primary device, compared with Canadians in other age groups, for activities ranging from reviewing emails to accessing social media or getting directions, even when at home (Catalyst, 2015; GlobalWebIndex, 2019). People born since 1994, who are now over 18, spend less time than previous generations engaged in inperson or face-to-face interactions with peers, including getting together with friends, going to parties, going out, dating, going to movies, or riding in cars for fun. In fact, they spend less than one hour a day engaging in in-person social interaction (Twenge, Spitzberg, & Campbell, 2019). As isolated as that sounds, however, they are still socially connected as they spend, on average, 4 hours and 15 minutes on their smart phones each day, which is the highest of any age group (GlobalWebIndex, 2019). It might seem that virtual interaction and communication is replacing in-person social interaction but it is actually more complicated than that, because levels of in-person social interaction are positively correlated with social media use, suggesting that highly-connected people use many means of communication. As well, general levels of reported loneliness have increased dramatically since 2011 and yet adolescents and emerging adults who are lowest in inperson social interaction and highest in social media use tend to report feeling the most lonely (Twenge et al., 2019). As this text was being prepared, as we were trying to sort out just what research questions needed to be asked to better understand the effects of non-in-person communication, we essentially entered a huge social experiment brought on by the outbreak of the COVID-19 pandemic. Most colleges and universities had shifted all of their courses from face-to-face to online, many people were working from home, and all were being asked to engage in social distancing by maintaining a bicycle-length distance between one another and refraining from sociocultural contact norms, like handshaking, cheek kissing, hugging, or touching. The meaning of those sorts of social norms may seem obscure but they are important parts of communication and stopping them suddenly can be quite disorienting. Classes were being run remotely either as recorded podcasts or videocasts or live using services like Zoom, Skype, or FaceTime, and meetings were happening online as well. For students, whose overall levels of anxiety were already historically high, it was not yet clear whether this shift to almost 100 percent online social and academic living would add to or reduce levels of anxiety. As responses to the COVID-19 pandemic were unfolding globally, it was not clear what the spinoffs from this shift to such high levels of virtual social interaction would be. Some speculated that it could lead to a “social recession,” rife with loneliness and isolation (Murthy & Chen, 2020), but as this textbook was being written, it was too early to tell how the situation would unfold. What is worth remembering is that our use of language— spoken communication—is one of our most amazing and creative evolutionary adaptations. Given this, while it was safe to say that things would be quite different during the pandemic, it will also likely be quite fascinating to note how humans adapt to our new communication realities and challenges. YouTube videos showing Italians in pandemic lockdown singing and playing music with one another on their balconies were only an early example of the sorts of creative social and communicative adaptation we will undoubtedly see much more of. Language evolved as a means for connecting socially and communicating, and creativity is an inherent part of the adaptive power of language. Language and thought are characteristics that distinguish humans from other creatures. Language enables us to communicate in a precise and often creative way. We also use language to tell stories or jokes. Language has allowed us, as a species, to learn from past generations, originally by oral storytelling and then by written language. Language is a critical component of human behaviour because it greatly facilitates progressive social interactions. Consider the difficulty involved in organizing a large group of people to build a city. Such a feat would be nearly impossible without the use of language. Although language is communicative, sometimes we use language only in our own heads. We often think using words, but many of our thoughts are not shared. Some people write extensively but only for themselves, never intending or wanting others to read their written words. Although the processes of language and thought overlap, a clear difference exists between them. In general, psychologists study these processes separately. Human thought is highly complex, varies from individual to individual, and takes on many different forms. The study of thought is a major component of cognitive psychology. As we saw in Chapter 1, the word cognition refers to a variety of mental processes that contribute to thinking and knowing. Cognition is involved in learning and memory, as well as in thinking. In this chapter, we will discuss a number of different types of thinking, which can involve accumulating knowledge, solving problems, making decisions, and even thinking about thinking. cognition mental processes of thinking and knowing.
Language LEARNING OBJECTIVE 1 Define language, describe how we learn languages, describe parts of the brain that are involved in language, and discuss differences and problems that can affect people’s language skills. What Is Language? Language, whether spoken, signed, or written, is a set of symbols used to communicate. We use symbols, mainly words, to convey our thoughts and desires to others who share an understanding of those symbols. Language can be divided into two main components: language production and language comprehension. Language production occurs when we generate thought through words. Speech involves the expression of language through sounds. Human language production is generative or creative; we make new sentences whenever we speak, rather than just restating old ones. In fact, humans have a remarkable capacity for producing new sentences, and we rarely repeat previously-heard sentences word-for-word. The ability to produce new sentences spontaneously and creatively is an important feature of human communication. We know that many other species communicate with sounds, but the vocalizations uttered by most species are inborn and do not change (see photo). A lion does not need to learn how to roar, for example, and it does not phrase its roar differently every time. language a set of symbols used to communicate. language production the structured and conventional expression of thoughts through words. speech the expression of language through sounds.
Language? . . . not These canaries may appear to be discussing how beautiful a day it is or how well their offspring fly. However, although the word-like sounds they emit involve communication (that is, the sharing of information), they do not amount to language. Very few species other than humans can learn new vocalizations, sounds produced in an effort to communicate (Oller et al., 2019; Bernabeu & Vogt, 2015). Vocal learning occurs in some species of songbirds (canaries, zebra finches), bats, aquatic mammals (whales and dolphins), and humans. It may come as a surprise that no primates other than humans learn language naturally, although monkeys and apes have an extensive repertoire of species-specific vocalizations and baboons are able to learn to recognize words (Fagot et al., 2019). However, apes that have learned some vocalizations are not capable of the complexities that characterize human language. Despite years of training in the laboratory, for example, no ape has ever learned to speak, as they lack the vocal apparatus that humans evolved over many thousands of years. Gorillas are able to use a range of signs to communicate. For example, the gorilla Koko, who passed away in 2018 at 46 years of age, learned over 1,000 American Sign Language-based signs (Gold & Watson, 2018; Perlman & Clark, 2015; Peng, Fouts, & Rumbaugh, 2019). (See photo.) See if you can understand Koko’s signs here: www.youtube.com/watch?v=SNuZ4OE6vCk. Alternatively, follow Sean Senechal’s approach to teaching your dog some basic signs—using K9Sign (Senechal, 2012).
Sign language Koko was able to use over 1,000 recognizable gestures from American Sign Language. Humans are also endowed with an impressive capacity for language comprehension, the ability to understand communicative vocalizations or gestures. We can generally comprehend fragments of sentences or words that are mispronounced. We can understand people who speak with accents (Bent & Atagi, 2017), people with speech impediments, such as lisps or stutters, as well as immature speech, such as the speech of toddlers (Hernández et al., 2019). Our ability to understand speech that is incomplete or unclear is related to the fact that much of language comprehension is automatic. Typically we understand spoken language without concentrating, which is the reason we are able to carry on a conversation with limited pauses before responding. language comprehension the process of understanding spoken, written, or signed language. Language Structure The study of speech can be divided into four general areas: phonology, semantics, syntax, and pragmatics. Figure 9.1 shows the building blocks of language. The smallest units of sound in any language are called phonemes, and the study of how sounds are put together to form words is called phonology. For example, the word tip has three phonemes—t, i, and p. The number of phonemes differs from language to language (Yu & Zellou, 2019). The English language has about 40 phonemes (give or take a few depending on the dialect). At one end of the spectrum is the language Pirahã, an Indigenous language of Brazilian people living in the Amazon, which has only 10 phonemes. At the other end of the spectrum is the Taa language (also known as !Xóõ), a language of Indigenous people of Botswana and Namibia, which has 141 phonemes. phoneme the smallest unit of sound in a language; an individual sound such as ba, da, or ta. phonology the study of how individual sounds or phonemes are used to produce language. Janet Werker at the University of British Columbia has demonstrated that speakers of one language often cannot distinguish sounds of other languages if their own language does not include the phoneme (Yeung, Chen, & Werker, 2013; Werker, 2018). For example, French does not include the h sound at the beginning of words. French speakers would say, “’Ave you ’eard about ’arry?” When learning English, French speakers will often overcompensate by voicing the h sounds in words where English speakers largely omit them, such as “hour” or “honour.” Such errors are particularly noticeable in older speakers learning a new language (in this case English). Later in this chapter we discuss how it is much easier to learn languages during an early stage of life. While phonemes are sounds, morphemes are the smallest units of language that convey meaning or function (Shi, 2014; Kuczaj & Barrett, 2012). For example, the word jumped has two morphemes. One is jump and the other is ed (the ed morpheme changes the meaning, indicating that the jumping has already taken place). Therefore, words can contain more than one morpheme, but each morpheme is not necessarily a word (that is, ed cannot stand alone and convey meaning). The study of the meaning of words is referred to as semantics. For example, if we say that it is “raining cats and dogs,” you do not look outside and expect to see animals falling from the sky. Instead, you know that this expression means that it is raining very heavily. The dictionary meaning of a word is referred to as its lexical meaning. Lexical meaning changes over time. Consider the word awful; it used to mean “full of awe,” but now means that something is extremely bad or unpleasant. Non-lexical sounds or words are things like hmmmm or ahhhh that require observational experience to understand how and when they are used in social interaction in one’s language community (Keevallik & Ogden, 2020). morpheme the smallest units of a language that convey meaning. semantics the study of how meaning in language is constructed of individual words and sentences. lexical meaning dictionary meaning of a word. Knowing the meaning of individual words is important, but a word’s meaning is often communicated through the position of the word in a sentence. For example, if you say that Joe kissed Kelly, then your listener knows that Joe was the giver of the kiss and that Kelly was the receiver. If, however, you say that Kelly kissed Joe, then the listener knows that Kelly was the giver of the kiss and that Joe was the receiver. As well, one word can mean two things; for example, the word blue can mean a colour or a depressed emotional state. When heard alone, it’s impossible to tell the intended meaning. However, when we hear blue in the context of a particular sentence, such as, “She wore a beautiful blue dress,” or, “He’s feeling blue today,” the distinction becomes instantly clear. The way in which words are constructed into sentences is referred to as syntax. syntax the system for using words (semantics) and word order to convey meaning (grammar). Phonology, semantics, and syntax bring us to the point where we have sounds, words, and sentences. Communication also requires adhering to social norms, such as speed of speech, responding at appropriate intervals, making eye contact, and using acceptable body language. These aspects of communication are called pragmatics, because they refer to the practical use of language. pragmatics the practical aspects of language usage, including speech pace, gesturing, and body language.
One aspect of pragmatics is our use of body language, or non-verbal communication (see photo). The way we move our hands, bodies, and faces can change the connotations of our speech. Suppose your instructor said, “I would like to meet with you after class.” If this statement was delivered with one raised eyebrow, a sneer, and arms folded across the chest, you would likely interpret it differently than if the instructor said the sentence with a warm smile, while leaning forward with hands on a desk. Some people are not aware of the body language they are using and unwittingly send the wrong message when they attempt to communicate. An employee may believe, for example, that a boss is making inappropriate advances because the boss is unaware of the message he or she sends by standing close and touching the worker’s arm while talking. Things like how close we stand to others as we interact with them also have meaning. Too close is interpreted as pushy or threatening and too far is interpreted as rude or dismissive, though all of those conventions were tossed out with the social distancing advice during the COVID-19 pandemic, which required both social and individual interpretive adjustments (Hadley, Brimijoin, & Whitmer, 2019; Judge, 2020). non-verbal communication body language.
Getting his message across Prime Minister Justin Trudeau’s embrace of the late Gord Downie during an Assembly of First Nations ceremony honouring the musician communicates his congratulations and support. Non-verbal communication seems to be acquired automatically, often by observing the actions of others. Non-verbal communication is related to, but not identical to, gesturing, which refers to communicative movements of the arms and hands. Gesturing facilitates speech production. While the ancient Greeks provided orators with explicit lessons in gesturing to enhance their speeches, studies have shown that gesturing appears to be innate (Byrne & Cochet, 2017; Zlatev, 2015). For example, people blind from birth, who have not had the chance to learn gestures by watching others, nevertheless use gestures when they speak. Gesturing is often difficult to inhibit; blind people will gesture even when they are talking to another blind person (Jelec & Jaworska, 2014; Fenlon, et al., 2019). Research has shown that blind students can be helped to grasp mathematical concepts or even learn to play the piano more quickly if they get information about their instructors’ gestures by having the instructor wear a haptic glove interface (a glove that records information about hand movements and touch) (Quek & Oliveira, 2013; Pala & Türker, 2019). How Language Develops You were probably too young at the time you started to speak your native language to remember learning it. Your parents may have proudly kept a record of your first words. If they did, they probably abandoned the list pretty soon, as it became too long very quickly. Within just a few years, almost every human baby goes from being incapable of speaking or understanding language to having an extensive vocabulary (see photo).
Baby talk Infants’ productive vocabulary goes from zero to 50 words in 18 months and over the same time frame their comprehension vocabulary increases to three times their production level. Prevocal learning Between 2 and 4 months of age, babies (with normal hearing) are capable of perceiving the phonemes of every language, including those that are not needed for the language(s) they will ultimately learn (Horst & von Koss Torkildsen, 2019). During this time, babies have a remarkable ability to distinguish among these sounds. Researchers investigated babies’ abilities to distinguish among different phonemes by training the babies to turn their heads toward an interesting visual reward when they hear a change in speech sounds. Results of studies by UBC’s Janet Werker and others using this type of training (which is a form of operant or instrumental conditioning, as described in Chapter 7) suggest that young babies can discern a much wider range of phonemes than older children or adults can (Werker, 1989). This ability declines, however, as babies begin to learn their native language (Sundara et al., 2018). With practice in only the phonemes of our native language, we lose the ability to distinguish among sounds that are only heard in other languages (Kuhl, 2010; Yule, 2017). This pruning of phoneme processing happens without specific training, and clearly suggests that infants arrive ready to notice, tune into, and acquire the language(s) being spoken around them. Cooing By about 2 months of age, babies begin to make a non-crying vocalization that consists largely of vowel-like sounds (e.g., o-o-o-o-u-u-u). Infants may also produce brief consonant-like sounds that sound somewhat like a k or g. Although infants occasionally produce these sounds when alone, they largely appear when the infant is interacting with someone else (Asada, 2016; Murray et al., 2016). Babbling By about 6 months, babies start to babble (Elmlinger, Schwade, & Goldstein, 2019). Babbling refers to the production of meaningless speech sounds either repetitively (e.g., da-da-da-da-da) or in a more mixed manner (e.g., pa-da-ca-ca-miden-bo). These vocalizations do not work as communication, but they do enable the infant to experiment with vocalizations in a way that gradually approaches their soon- to-be-acquired native language. All babies babble, including those who are deaf (Blamey & Sarant, 2013; Brice, Plotkin, & Reesman, 2016). First words By about 1 year, speaking begins, typically in the form of very simple words, such as mama, dada, or hi (Perlman, Fusaroli, Fein, & Naigles, 2017; Menn & Stoel-Gammon, 2017). At this early stage, the baby’s ability to comprehend is much greater than the ability to speak (see Figure 9.2). At about 1 year of age, the average baby can understand approximately 50 words, but he will not be able to speak that many words until about months later (Yule, 2017; Hansen & Broekhuizen, 2019). Oneyear-olds can often follow commands, such as, “Get the ball and bring it to mommy,” even though their spoken vocabulary may only include ball and mama. Telegraphic speech By age 2, toddlers in most language communities speak in very short (typically two-word) sentences. This is called telegraphic speech because, as in old-fashioned telegraph messages (for which senders were charged by the word), all but the essential words are omitted. Instead of saying, “I want a cookie,” a 2-year-old is more likely to simply say, “Want cookie.” The order of the words used varies by linguistic group (for example, “Give cookie” in English and “Cookie give” in Japanese) (Bloom, 2013). The dropped words are called grammatical morphemes and they are only dropped when they are not necessary to determine the meaning of the spoken phrase in their language community (Slobin, 2014). Pragmatics By 3 years of age, the average toddler has naturally acquired some practical information about language use, including the need to pause between sentences and the knowledge that certain sentences are statements, whereas others are requests (Matthews, 2014; Adamson, 2018). The average English-speaking 3-yearold vocabulary typically includes about 1,000 words (Huttenlocher et al., 1991; Bleses et al., 2016). Grammar By age 4, children have automatically absorbed many of the rules of grammar, even though they have received no formal education about the grammar of their native languages (Tager-Flusberg, 2001; Justice et al., 2018). As discussed below, some of the early stages of reading often emerge around this time when children are exposed to written words at home or preschool. By age 6, the average child uses almost 3,000 words and likely understands a great many more, about 14,000 words (depending on the amount of language they were previously exposed to—see the feature, Practically Speaking 9.1: Poverty and Language Development). By age 9, practical aspects of language emerge, such as inferring meaning of obscure language, interpreting metaphors, and understanding sophisticated humour (Wellman, 2014). babbling babies’ production of meaningless sounds. telegraphic speech speech that consists of minimalistic sentences; characterizes early toddlerhood and is the first evidence of sentence formation.
Babies’ comprehension of words Babies can comprehend more words than they can speak. One-year-old babies understand about 50 words, but will not be able to speak them until about months later. Adapted with permission from Fenson, L., Dale, P.S., Reznick, J.S., et al. (1994). Variability in early communicative development. Monographs of the Society for Research in Child Development, 59(5, Serial No. 173), Blackwell Publishers; based on Lilienfeld, S., Lynn, S., Namy, L., & Wolf, N. (2008). Psychology: From inquiry to understanding. Boston: Pearson/Allyn & Bacon, Figure 8-3, p. 325. Even though the majority of language learning occurs relatively early in life, vocabulary and its usage can continue to increase in size and sophistication for decades to come. In studying for the Graduate Record Exam (part of the application process for many graduate programs, including psychology) or other university- or college-admission exams, many young adults find themselves learning words they haven’t used before. Vocabulary can increase throughout adulthood, and seems to be one type of memory that is not adversely affected by the normal aging process. Elderly people with slowed reaction times and impaired memory for events in their own lives often score as high, if not higher, than young adults on vocabulary tests (Moscoso del Prado Martín, 2017; Salthouse, 2017). 9.1 Practically Speaking Poverty and Language Development Children from socio-economically disadvantaged backgrounds often struggle in academic settings. In fact, several studies suggest that poor children have deficient vocabularies when they first enter elementary school, and that these differences often get exaggerated as the years pass because vocabulary builds on itself (Fernald, Marchman, & Weisleder, 2012; Schwab & Lew-Williams, 2016). Research has shown that the initial language deficits of poor children are due to differences in their linguistic environments. On average, as infants, toddlers, and young children, students from lower socio-economic status (SES) households are exposed to fewer words than are students from households with higher socio-economic status. As shown in the table, one study found that, in any given hour, children in poor homes heard fewer than half the number of words than children in high SES homes did (Fernald et al., 2012). In addition, much more of the speech to which poor children were exposed was prohibitive; for example, when a parent says, “Stop it!” or “Don’t touch that.” The exact reasons why poor parents communicate less, as well as less positively, with their children remain unknown. The stress of poverty and the potential lack of suitable role models for parents (parenting skills are largely acquired through one’s own upbringing) are two likely causes. Work by Monique Sénéchal and Jo-Anne LeFevre (2002, 2014) at Carleton University highlights the good news that the problem of reduced vocabularies in lower SES children can be prevented by preschool intervention that includes educating parents about the benefits of talking and reading to children in the home. Research in this area also highlights one of the key challenges with human research: we are a lot better at carefully observing human behaviour (the whats, as in what is going on?) than we are at understanding the reasons for observed behaviour (the whys). Finding out the underlying causes of human behaviour is understandably harder as we are ethically unable to experiment on many aspects of human condition. So, we can see that there appear to be SES differences in parent–child communication, but at the same time we are not really clear on why those observed differences exist. It is especially important that we identify what the causes are in situations like this, as we may be able to design intervention programs to lessen or remove conditions of disadvantage.
Theories of Language Development Think about experiences you have had building your vocabulary, perhaps to take exams or as part of an English course. You may also have had experience learning a second or third language later in your education, perhaps starting in late elementary school or even in high school. In either situation, whether expanding your vocabulary in your first language or adding an entirely new language, you probably experienced a much slower learning rate than you did when you learned your first language as a very young child. Language-related learning later in life probably also required concentrated attention to your studies; it most likely did not occur automatically. The ease with which language is acquired by human infants has led many researchers to speculate that language has a biological basis. The linguist Noam Chomsky was among the first to suggest that language learning is built into our brains (Chomsky, 1964). The brain does appear to be set up to understand and communicate using language. As we have noted, the ability to detect all phonemes used in any human language exists in all human babies (as long as their hearing is intact). Other studies have also shown that the very young brain is wired to acquire language rapidly and automatically, because it is in a highly plastic, or changeable, state, ready to absorb new information about language. As humans grow and reach adulthood, the brain maintains the ability to change, but that ability diminishes (Johnson & Newport, 1989; Šarić & Obad, 2015)—language learning becomes much slower and requires more effort. Chomsky described our early capacity for language learning as working as if we had a sort of language acquisition device built in to our brains. As we have seen, the influence of this theoretic “device” may fade as we age and become more cognitively aware of our learning processes. Psychologists often refer to the childhood years before age 13 as an especially important period for language acquisition (Finn, Lee, Kraus, & Kam, 2014; Werker & Hensch, 2015). Some debate exists as to whether language systems have a critical or a sensitive period (Patton, Blundon, & Zakharenko, 2019). Recall from Chapter 4 that a critical period is a window of time during which certain influences are necessary for appropriate formation of the brain. After the critical period, these influences are no longer capable of having as profound an impact on the brain. A sensitive period is a developmental time during which the brain is more susceptible to influences. After the sensitive period, change can still occur, but it doesn’t happen as readily (Cheung, Chudek, & Heine, 2011). critical period a window of time in development during which certain influences are necessary for appropriate formation of the brain. sensitive period a point in development during which the brain is more susceptible to influences.
Baby sign This mother is using child-directed speech to communicate with her toddler, including special intonations in her voice and a modified form of sign language that is simple so her toddler can follow it and that focuses attention on what the mother is talking about. The toddler is also using the same “baby sign” as part of their interaction. As we have seen, we can still expand our vocabularies or learn new languages later in life, suggesting that, in normal cases, we go through more of a sensitive period than a critical period for language learning. Some evidence, however, such as from the sad case of Genie described in the next section, suggests that there is a critical period during which we must have some language input or we do not acquire normal fluency with speech and, in fact, may miss out on the opportunity to develop a working understanding of the underlying syntactic features of language. It’s clear that our brains have a biological propensity to help us acquire at least one language, but the process of language learning is not exclusively innate. Much evidence suggests that the environment plays a critical role as well. Early behaviourists, including B. F. Skinner (1957), suggested that language is acquired as a result of instrumental conditioning. They argued that toddlers are rewarded with praise for producing appropriate speech, and ignored or scolded for failure to do so. As you may have noticed, however, parents, caregivers, and other older people do not usually systematically reward toddlers for correct speech. The 2-year-old who says, “Want cookie,” is just as likely to get one as another child who can ask, “Please, may I have a cookie?” Conditioning alone, therefore, cannot explain language acquisition (Chomsky, 1959; Palmer, 2006). Interactive theories suggest that experience interacts with biological development to enhance and guide language learning (Lewis et al., 2016; Chung, Chen, & Geva, 2019). As we have described, for instance, if a baby isn’t exposed to certain phonemes, her capacity to distinguish among these sounds diminishes over time. The social environments of most babies and young children also typically offer a high degree of very interactive speech. Most adults in most cultures talk to babies with a special intonation in their voices; a high-pitched and sometimes exaggerated speech that is spoken directly to an infant or child is called child-directed speech (Golinkoff, Can, Soderstrom & Hirsch-Pasek, 2015). The patterns of child-directed speech are often rich in emotions, which may have the added benefit of fostering a close emotional relationship between caregiver and child, thus enhancing the quality and quantity of communication. child-directed speech speech characterized by exaggerated emotional responses and a slower pace that is cross-culturally common among caregivers communicating with babies and young children. Child-directed speech is also observed when parents use sign language to communicate with babies, though this is different than the “baby sign” shown in the photo. Whether the adult, child, or both are deaf, the use of sign language during the learning phase naturally takes the form of child-directed speech—slower in the formation of the hand signs, with longer pauses in between signs and exaggeration of facial expressions of emotions (Lieberman, Hatrak, & Mayberry, 2014). Child-directed speech arises naturally; people adopt it without any formal instruction, suggesting that humans seem to have a biological predisposition to teach effective communication to the very young (Vouloumanos & Gelfand, 2013; Adamson, 2018).